{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying MNIST with a simple model and quantum embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by:  https://www.kaggle.com/code/geekysaint/solving-mnist-using-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the Boson Sampler\n",
    "import perceval as pcvl\n",
    "#import perceval.providers.scaleway as scw  # Uncomment to allow running on scaleway\n",
    "\n",
    "from math import comb\n",
    "from typing import Iterable\n",
    "from functools import lru_cache\n",
    "\n",
    "# for the machine learning model\n",
    "import torch\n",
    "import torchvision ## Contains some utilities for working with the image data\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Boson Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BosonSampler:\n",
    "    \n",
    "    def __init__(self, m: int, n: int, postselect: int = None, session : pcvl.ISession = None):\n",
    "        \"\"\"\n",
    "        A class able to embed a tensor using a photonic circuit wit√®h thresholded outputs.\n",
    "        \n",
    "        :param m: The number of modes of the circuit. Larger values allow more values in the embedded tensor.\n",
    "        :param n: The number of photons to input in the circuit.\n",
    "        :param postselect: The minimum number of detected photons to count an output state as valid. Defaults to n.\n",
    "        :param session: An optional scaleway session. If provided, simulations will be launched remotely, else they will run locally.\n",
    "        \"\"\"\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        assert n <= m, \"Got more photons than modes, can only input 0 or 1 photon per mode\"\n",
    "        self.postselect = postselect or n\n",
    "        assert self.postselect <= n, \"Cannot postselect with more photons than the input number of photons\"\n",
    "        self.session = session\n",
    "\n",
    "    @property\n",
    "    def _nb_parameters_needed(self) -> int:\n",
    "        \"\"\"Returns the number of phase shifters in the circuit. Only used internally\"\"\"\n",
    "        return self.m * (self.m - 1)\n",
    "    \n",
    "    @property\n",
    "    def nb_parameters(self) -> int:\n",
    "        \"\"\"Returns the maximum number of values in the input tensor.\n",
    "          This corresponds to the number of phase shifters that can affect the output probabilities in the circuit\"\"\"\n",
    "        return self._nb_parameters_needed - (self.m // 2)  # Doesn't count the last layer of PS as it doesn't change anything\n",
    "    \n",
    "    def create_circuit(self, parameters: Iterable[float] = None) -> pcvl.Circuit:\n",
    "        \"\"\"Creates a generic interferometer using a list of phases of size self._nb_parameters_needed.\n",
    "        If no list is provided, the circuit is built with perceval parameters\"\"\"\n",
    "        if parameters is None:\n",
    "            parameters = [p for i in range(self.m * (self.m - 1) // 2)\n",
    "                            for p in [pcvl.P(f\"phi_{2 * i}\"), pcvl.P(f\"phi_{2 * i + 1}\")]]\n",
    "        return pcvl.GenericInterferometer(self.m, lambda i: (pcvl.BS()\n",
    "                                                             .add(0, pcvl.PS(parameters[2 * i]))\n",
    "                                                             .add(0, pcvl.BS())\n",
    "                                                             .add(0, pcvl.PS(parameters[2 * i + 1]))\n",
    "                                                             )\n",
    "                                          )\n",
    "        \n",
    "    def embed(self, t: torch.tensor, n_sample: int) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Embeds the tensor t using its values as phases in a circuit, and returns the output probability distribution\n",
    "\n",
    "        :param t: The tensor to be embedded, with values between 0 and 1\n",
    "        :param n_sample: The number of samples used to estimate the output probability distribution. Not used if running on a simulator\n",
    "        :return: A 1D tensor of size self.embedding_size representing the output probability distribution, estimated using n_sample\"\"\"\n",
    "\n",
    "        t = t.reshape(-1)  # We need to see t as a list of values\n",
    "        if len(t) > self.nb_parameters:\n",
    "            raise ValueError(f\"Got too many parameters (got {len(t)}, maximum {self.nb_parameters})\")\n",
    "        \n",
    "        # We need to complete the tensor to have the good number of phases\n",
    "        z = torch.zeros(self._nb_parameters_needed - len(t))\n",
    "        if len(z):\n",
    "            t = torch.cat((t, z), 0)\n",
    "            \n",
    "        t = t * 2 * torch.pi  # Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\n",
    "        \n",
    "        res = self.run(t, n_sample)  # This is a dict with states as keys and probabilities as values\n",
    "        \n",
    "        return self.translate_results(res)  # We need to transform this dict into a tensor\n",
    "        \n",
    "    @property\n",
    "    def embedding_size(self) -> int:\n",
    "        \"\"\"Size of the returned tensor. This is the number of possible output states\"\"\"\n",
    "        # For thresholded output, this is the number of binary numbers having at least self.postselect 1s\n",
    "        s = 0\n",
    "        for k in range(self.postselect, self.n + 1):\n",
    "            s += comb(self.m, k)\n",
    "        return s\n",
    "        \n",
    "    def translate_results(self, res: pcvl.BSDistribution) -> torch.tensor:\n",
    "        \"\"\"Transforms the perceval results into a list of probabilities, where each output is always represented at the same position\"\"\"\n",
    "        \n",
    "        # First, we generate a list of all possible output states\n",
    "        state_list = self.generate_state_list()\n",
    "        \n",
    "        # Then we take the probabilities from the BSD in the order of the list\n",
    "        t = torch.zeros(self.embedding_size)\n",
    "        for i, state in enumerate(state_list):\n",
    "            t[i] = res[state]\n",
    "            \n",
    "        return t\n",
    "        \n",
    "    @lru_cache  # Always the same, no need to compute it each time\n",
    "    def generate_state_list(self) -> list:\n",
    "        \"\"\"Generate a list of all possible output states\"\"\"\n",
    "        res = []\n",
    "        for k in range(self.postselect, self.n + 1):\n",
    "            res += self._generate_state_list_k(k)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def _generate_state_list_k(self, k) -> list:\n",
    "        \"\"\"Generate all binary states of size self.m having exactly *k* 1s\"\"\"\n",
    "        return list(map(pcvl.BasicState, pcvl.utils.qmath.distinct_permutations(k * [1] + (self.m - k) * [0])))\n",
    "        \n",
    "        \n",
    "    def prepare_processor(self, processor, parameters: Iterable[float]) -> None:\n",
    "        \"\"\"Give the important info to the processor\"\"\"\n",
    "        processor.set_circuit(self.create_circuit(parameters))\n",
    "        processor.min_detected_photons_filter(self.postselect)\n",
    "        processor.thresholded_output(True)\n",
    "        \n",
    "        # Evenly spaces the photons\n",
    "        input_state = self.m * [0]\n",
    "        places = torch.linspace(0, self.m - 1, self.n)\n",
    "        for photon in places:\n",
    "            input_state[int(photon)] = 1\n",
    "        input_state = pcvl.BasicState(input_state)\n",
    "        \n",
    "        processor.with_input(input_state)\n",
    "        \n",
    "    def run(self, parameters: Iterable[float], samples: int) -> pcvl.BSDistribution:\n",
    "        \"\"\"Samples and return the raw results, using the parameters as circuit phases\"\"\"\n",
    "        if self.session is not None:\n",
    "            proc = self.session.build_remote_processor()\n",
    "\n",
    "        else:\n",
    "            # Local simulation\n",
    "            proc = pcvl.Processor(\"SLOS\", self.m)\n",
    "\n",
    "        self.prepare_processor(proc, parameters)\n",
    "\n",
    "        sampler = pcvl.algorithm.Sampler(proc, max_shots_per_call=samples)\n",
    "        res = sampler.probs(samples)\n",
    "            \n",
    "        return res[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BosonSampler(30, 2)\n",
    "bs.embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_partial(Dataset):\n",
    "    def __init__(self, data = r'.\\data', transform=None, split = 'train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: path to dataset folder which contains train.csv and val.csv\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample (e.g., data augmentation or normalization)\n",
    "            split: 'train' or 'val' to determine which set to download\n",
    "        \"\"\"\n",
    "        self.data_dir = data\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        \n",
    "        if split == 'train':\n",
    "            filename = os.path.join(self.data_dir,'train.csv')\n",
    "        elif split == 'val':\n",
    "            filename = os.path.join(self.data_dir,'val.csv')\n",
    "        else:\n",
    "            raise AttributeError(\"split!='train' and split!='val': split must be train or val\")\n",
    "        \n",
    "        self.df = pd.read_csv(filename)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        l = len(self.df['image'])\n",
    "        return l\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.df['image'].iloc[idx]\n",
    "        label = self.df['label'].iloc[idx]\n",
    "        # string to list\n",
    "        img_list = re.split(r',', img)\n",
    "        # remove '[' and ']'\n",
    "        img_list[0] = img_list[0][1:]\n",
    "        img_list[-1] = img_list[-1][:-1]\n",
    "        # convert to float\n",
    "        img_float = [float(el) for el in img_list]\n",
    "        # convert to image\n",
    "        img_square = torch.unflatten(torch.tensor(img_float),0,(1,28,28))\n",
    "        if self.transform is not None:\n",
    "            img_square = self.transform(img_square)\n",
    "        return img_square, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to uncomment if you want to use the whole MNIST dataset and download it\n",
    "# # if you need to download MNIST\n",
    "# dataset = MNIST(root = '/home/jupyter-pemeriau/scaleway_demo/mnist-data/', download = True)\n",
    "# print(f\"Total length of dataset = {len(dataset)}\")\n",
    "\n",
    "# # to load the useful dataset\n",
    "# mnist_dataset = MNIST(root = '/home/jupyter-pemeriau/scaleway_demo/mnist-data/', train = True, transform = transforms.ToTensor())\n",
    "# len_dataset = len(mnist_dataset)\n",
    "\n",
    "# # TODO: here, you can chose the proportions of the dataset to use for training and validation\n",
    "# train_split, val_split = 0.005, 0.0001\n",
    "# train_size, val_size = int(train_split*len_dataset), int(val_split*len_dataset)\n",
    "# not_used = len_dataset - train_size - val_size\n",
    "# train_dataset, val_dataset, not_used_dataset = random_split(mnist_dataset, [train_size, val_size ,not_used] )\n",
    "# print(\"length of Train Datasets: \", len(train_dataset))\n",
    "# print(\"length of Validation Datasets: \", len(val_dataset))\n",
    "\n",
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy of the model\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim = 1)\n",
    "    return(torch.tensor(torch.sum(preds == labels).item()/ len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self, device = 'cpu', embedding_size = 0):\n",
    "        super().__init__()\n",
    "        input_size = 28 * 28\n",
    "        num_classes = 10\n",
    "        self.device = device\n",
    "        self.embedding_size = embedding_size\n",
    "        if self.embedding_size:\n",
    "            input_size += embedding_size #considering 30 photons and 2 modes\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, xb, emb = None):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        if self.embedding_size and emb is not None:\n",
    "            # concatenation of the embeddings and the input images\n",
    "            xb = torch.cat((xb,emb),dim=1)\n",
    "        out = self.linear(xb)\n",
    "        return(out)\n",
    "    \n",
    "    def training_step(self, batch, emb = None):\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(self.device), labels.to(self.device)\n",
    "        if self.embedding_size:\n",
    "            out = self(images, emb.to(self.device)) ## Generate predictions\n",
    "        else:\n",
    "            out = self(images) ## Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) ## Calculate the loss\n",
    "        acc = accuracy(out, labels)\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, emb =None):\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(self.device), labels.to(self.device)\n",
    "        if self.embedding_size:\n",
    "            out = self(images, emb.to(self.device)) ## Generate predictions\n",
    "        else:\n",
    "            out = self(images) ## Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return({'val_loss':loss, 'val_acc': acc})\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return({'val_loss': epoch_loss.item(), 'val_acc' : epoch_acc.item()})\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "        return result['val_loss'], result['val_acc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of the model\n",
    "def evaluate(model, val_loader, bs: BosonSampler = None):\n",
    "    if model.embedding_size:\n",
    "        outputs = []\n",
    "        for step, batch in enumerate(tqdm(val_loader)):\n",
    "            # embedding in the BS\n",
    "            images, labs = batch\n",
    "            images = images.squeeze(0).squeeze(0)\n",
    "            t_s = time.time()\n",
    "            embs = bs.embed(images,1000)\n",
    "            outputs.append(model.validation_step(batch, emb=embs.unsqueeze(0)))\n",
    "    else:\n",
    "        outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return(model.validation_epoch_end(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training curves (accuracy and loss) and save them in 'training_curves.png'\n",
    "def plot_training_metrics(train_acc,val_acc,train_loss,val_loss):\n",
    "    fig, axes = plt.subplots(1,2,figsize = (15,5))\n",
    "    X = [i for i in range(len(train_acc))]\n",
    "    names = [str(i+1) for i in range(len(train_acc))]\n",
    "    axes[0].plot(X,train_acc,label = 'training')\n",
    "    axes[0].plot(X,val_acc,label = 'validation')\n",
    "    axes[0].set_xlabel(\"Epochs\")\n",
    "    axes[0].set_ylabel(\"ACC\")\n",
    "    axes[0].set_title(\"Training and validation accuracies\")\n",
    "    axes[0].grid(visible = True)\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(X,train_loss,label = 'training')\n",
    "    axes[1].plot(X,val_loss,label = 'validation')\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].set_ylabel(\"Loss\")\n",
    "    axes[1].set_title(\"Training and validation losses\")\n",
    "    axes[1].grid(visible = True)\n",
    "    axes[1].legend()\n",
    "    axes[0].set_xticks(ticks=X,labels = names)\n",
    "    axes[1].set_xticks(ticks=X,labels = names)\n",
    "    fig.savefig(\"training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def fit(epochs, lr, model, train_loader, val_loader, bs: BosonSampler, opt_func = torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    # creation of empty lists to store the training metrics\n",
    "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        training_losses, training_accs = 0, 0\n",
    "        ## Training Phase\n",
    "        for step, batch in enumerate(tqdm(train_loader)):\n",
    "            # embedding in the BS\n",
    "            if model.embedding_size:\n",
    "                images, labs = batch\n",
    "                images = images.squeeze(0).squeeze(0)\n",
    "                t_s = time.time()\n",
    "                embs = bs.embed(images,1000)\n",
    "                loss,acc = model.training_step(batch,emb = embs.unsqueeze(0))\n",
    "\n",
    "            else:\n",
    "                loss,acc = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            training_losses+=int(loss.detach())\n",
    "            training_accs+=int(acc.detach())\n",
    "            if model.embedding_size and step%100==0:\n",
    "                print(f\"STEP {step}, Training-acc = {training_accs/(step+1)}, Training-losses = {training_losses/(step+1)}\")\n",
    "        \n",
    "        ## Validation phase\n",
    "        result = evaluate(model, val_loader, bs)\n",
    "        validation_loss, validation_acc = result['val_loss'], result['val_acc']\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "        ## summing up all the training and validation metrics\n",
    "        training_loss = training_losses/len(train_loader)\n",
    "        training_accs = training_accs/len(train_loader)\n",
    "        train_loss.append(training_loss)\n",
    "        train_acc.append(training_accs)\n",
    "        val_loss.append(validation_loss)\n",
    "        val_acc.append(validation_acc)\n",
    "\n",
    "        # plot training curves\n",
    "        plot_training_metrics(train_acc,val_acc,train_loss,val_loss)\n",
    "    return(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definition of the BosonSampler\n",
    "# here, we use 30 photons and 2 modes\n",
    "\n",
    "bs = BosonSampler(30, 2, postselect = 2, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs.nb_parameters}, and embedding size = {bs.embedding_size}\")\n",
    "\n",
    "#to display it\n",
    "pcvl.pdisplay(bs.create_circuit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define device to run the model\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and send it to the appropriate device\n",
    "# set embedding_size = bs.embedding_size if you want to use the boson sampler in input of the model\n",
    "model = MnistModel(device = device)\n",
    "# model = MnistModel(device = device, embedding_size = bs.embedding_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the chosen parameters\n",
    "experiment = fit(epochs = 5, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end session if needed\n",
    "if session is not None:\n",
    "    session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
