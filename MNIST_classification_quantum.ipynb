{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying MNIST with a simple model and quantum embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by:  https://www.kaggle.com/code/geekysaint/solving-mnist-using-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the Boson Sampler\n",
    "import perceval as pcvl\n",
    "#import perceval.providers.scaleway as scw\n",
    "\n",
    "import torch\n",
    "from math import comb\n",
    "\n",
    "from typing import Iterable\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "# for the machine learning model\n",
    "import torch\n",
    "import torchvision ## Contains some utilities for working with the image data\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Boson Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BosonSampler:\n",
    "    \n",
    "    def __init__(self, m: int, n: int, postselect: int = None, session = None):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        assert n <= m, \"Got more photons than modes, can only input 1 photon per mode\"\n",
    "        self.postselect = postselect or n\n",
    "        self.session = session\n",
    "    \n",
    "    @property\n",
    "    def nb_parameters(self):\n",
    "        return self.m * (self.m - 1) - (self.m // 2)  # Doesn't count the last layer of PS as it doesn't change anything\n",
    "    \n",
    "    @property\n",
    "    def nb_parameters_needed(self):\n",
    "        return self.m * (self.m - 1)\n",
    "    \n",
    "    def create_circuit(self, parameters: Iterable[float] = None):\n",
    "        if parameters is None:\n",
    "            parameters = [p for i in range(self.m * (self.m - 1) // 2)\n",
    "                            for p in [pcvl.P(f\"phi_{2 * i}\"), pcvl.P(f\"phi_{2 * i + 1}\")]]\n",
    "        return pcvl.GenericInterferometer(self.m, lambda i: (pcvl.BS()\n",
    "                                                             .add(0, pcvl.PS(parameters[2 * i]))\n",
    "                                                             .add(0, pcvl.BS())\n",
    "                                                             .add(0, pcvl.PS(parameters[2 * i + 1]))\n",
    "                                                             )\n",
    "                                          )\n",
    "        \n",
    "    def embed(self, t: torch.tensor, n_sample: int):\n",
    "        \"\"\"t is supposed to be normalized\"\"\"\n",
    "        t = t.reshape(-1)  # TODO: check if this is a good way to do this\n",
    "        if len(t) > self.nb_parameters:\n",
    "            raise ValueError(f\"Got too many parameters (got {len(t)}, maximum {self.nb_parameters})\")\n",
    "        z = torch.zeros(self.nb_parameters_needed - len(t))\n",
    "        if len(z):\n",
    "            t = torch.cat((t, z), 0)\n",
    "            \n",
    "        t = t * 2 * torch.pi\n",
    "        \n",
    "        res = self.run(t, n_sample)\n",
    "        \n",
    "        return self.translate_results(res)\n",
    "        \n",
    "    @property\n",
    "    def embedding_size(self) -> int:\n",
    "        # For thresholded output, this is the number of binary numbers having at least self.postselect 1s\n",
    "        s = 0\n",
    "        for k in range(self.postselect, self.n + 1):\n",
    "            s += comb(self.m, k)\n",
    "        return s\n",
    "        \n",
    "    def translate_results(self, res: pcvl.BSDistribution) -> torch.tensor:\n",
    "        t = torch.zeros(self.embedding_size)\n",
    "        \n",
    "        # First, we generate a list of all possible output states\n",
    "        state_list = self.generate_state_list()\n",
    "        \n",
    "        # Then we take the probabilities from the BSD in the order of the list\n",
    "        for i, state in enumerate(state_list):\n",
    "            t[i] = res[state]\n",
    "            \n",
    "        return t\n",
    "        \n",
    "    @lru_cache  # Always the same, no need to compute it each time\n",
    "    def generate_state_list(self):\n",
    "        res = []\n",
    "        for k in range(self.postselect, self.n + 1):\n",
    "            res += self._generate_state_list_k(k)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def _generate_state_list_k(self, k):\n",
    "        # generates all binary states of size self.m having k 1s\n",
    "        return list(map(pcvl.BasicState, pcvl.utils.qmath.distinct_permutations(k * [1] + (self.m - k) * [0])))\n",
    "        \n",
    "        \n",
    "    def prepare_processor(self, processor, parameters: Iterable[float]):\n",
    "        processor.set_circuit(self.create_circuit(parameters))\n",
    "        processor.min_detected_photons_filter(self.postselect)\n",
    "        processor.thresholded_output(True)\n",
    "        \n",
    "        # Evenly spaces the photons\n",
    "        input_state = self.m * [0]\n",
    "        places = torch.linspace(0, self.m - 1, self.n)\n",
    "        for photon in places:\n",
    "            input_state[int(photon)] = 1\n",
    "        input_state = pcvl.BasicState(input_state)\n",
    "        \n",
    "        processor.with_input(input_state)\n",
    "        \n",
    "    def run(self, parameters: Iterable[float], samples: int) -> pcvl.BSDistribution:\n",
    "        \"\"\"Samples and return the raw results\"\"\"\n",
    "        if self.session is not None:\n",
    "            proc = self.session.build_remote_processor()\n",
    "\n",
    "        else:\n",
    "            # Local simulation\n",
    "            proc = pcvl.Processor(\"SLOS\", self.m)\n",
    "\n",
    "        self.prepare_processor(proc, parameters)\n",
    "\n",
    "        sampler = pcvl.algorithm.Sampler(proc, max_shots_per_call=samples)\n",
    "        res = sampler.probs(samples)\n",
    "            \n",
    "        return res[\"results\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to download MNIST\n",
    "dataset = MNIST(root = '/home/jupyter-pemeriau/scaleway_demo/mnist-data/', download = True)\n",
    "print(f\"Total length of dataset = {len(dataset)}\")\n",
    "\n",
    "# to load the useful dataset\n",
    "mnist_dataset = MNIST(root = '/home/jupyter-pemeriau/scaleway_demo/mnist-data/', train = True, transform = transforms.ToTensor())\n",
    "len_dataset = len(mnist_dataset)\n",
    "\n",
    "# TODO: here, you can chose the proportions of the dataset to use for training and validation\n",
    "train_split, val_split = 0.005, 0.0001\n",
    "train_size, val_size = int(train_split*len_dataset), int(val_split*len_dataset)\n",
    "not_used = len_dataset - train_size - val_size\n",
    "train_dataset, val_dataset, not_used_dataset = random_split(mnist_dataset, [train_size, val_size ,not_used] )\n",
    "print(\"length of Train Datasets: \", len(train_dataset))\n",
    "print(\"length of Validation Datasets: \", len(val_dataset))\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy of the model\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim = 1)\n",
    "    return(torch.tensor(torch.sum(preds == labels).item()/ len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self, device = 'cpu', use_quantum = False):\n",
    "        super().__init__()\n",
    "        input_size = 28 * 28\n",
    "        num_classes = 10\n",
    "        self.device = device\n",
    "        self.use_quantum = use_quantum\n",
    "        if self.use_quantum:\n",
    "            input_size = 28 * 28 + 435 #considering 30 photons and 2 modes\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, xb, emb = None):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        if self.use_quantum and emb is not None:\n",
    "            # concatenation of the embeddings and the input images\n",
    "            xb = torch.cat((xb,emb),dim=1)\n",
    "        out = self.linear(xb)\n",
    "        return(out)\n",
    "    \n",
    "    def training_step(self, batch, emb = None):\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(self.device), labels.to(self.device)\n",
    "        if self.use_quantum:\n",
    "            out = self(images, emb.to(self.device)) ## Generate predictions\n",
    "        else:\n",
    "            out = self(images) ## Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) ## Calculate the loss\n",
    "        acc = accuracy(out, labels)\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch, emb =None):\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(self.device), labels.to(self.device)\n",
    "        if self.use_quantum:\n",
    "            out = self(images, emb.to(self.device)) ## Generate predictions\n",
    "        else:\n",
    "            out = self(images) ## Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return({'val_loss':loss, 'val_acc': acc})\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return({'val_loss': epoch_loss.item(), 'val_acc' : epoch_acc.item()})\n",
    "    \n",
    "    def epoch_end(self, epoch,result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "        return result['val_loss'], result['val_acc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of the model\n",
    "def evaluate(model, val_loader):\n",
    "    if model.use_quantum:\n",
    "        outputs = []\n",
    "        for step, batch in enumerate(tqdm(val_loader)):\n",
    "            # embedding in the BS\n",
    "            images, labs = batch\n",
    "            images = images.squeeze(0).squeeze(0)\n",
    "            t_s = time.time()\n",
    "            embs = bs.embed(images,1000)\n",
    "            outputs.append(model.validation_step(batch, emb=embs.unsqueeze(0)))\n",
    "    else:\n",
    "        outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    #val_loss, val_acc = model.validation_epoch_end(outputs)\n",
    "    return(model.validation_epoch_end(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics(train_acc,val_acc,train_loss,val_loss):\n",
    "    fig, axes = plt.subplots(1,2,figsize = (15,5))\n",
    "    X = [i for i in range(len(train_acc))]\n",
    "    axes[0].plot(X,train_acc,label = 'training')\n",
    "    axes[0].plot(X,val_acc,label = 'validation')\n",
    "    axes[0].set_xlabel(\"Epochs\")\n",
    "    axes[0].set_ylabel(\"ACC\")\n",
    "    axes[0].set_title(\"Training and validation accuracies\")\n",
    "    axes[0].grid(visible = True)\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(X,train_loss,label = 'training')\n",
    "    axes[1].plot(X,val_loss,label = 'validation')\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].set_ylabel(\"Loss\")\n",
    "    axes[1].set_title(\"Training and validation losses\")\n",
    "    axes[1].grid(visible = True)\n",
    "    axes[1].legend()\n",
    "    fig.savefig(\"training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        training_losses, training_accs = 0, 0\n",
    "        ## Training Phas\n",
    "        for step, batch in enumerate(tqdm(train_loader)):\n",
    "            # embedding in the BS\n",
    "            if model.use_quantum:\n",
    "                images, labs = batch\n",
    "                images = images.squeeze(0).squeeze(0)\n",
    "                t_s = time.time()\n",
    "                embs = bs.embed(images,1000)\n",
    "                loss,acc = model.training_step(batch,emb = embs.unsqueeze(0))\n",
    "            #print(f\"Null elements {torch.isnan(embs).any()}\")\n",
    "            #print(f\"embs of shape = {embs.shape} in {time.time()-t_s}\")\n",
    "            else:\n",
    "                loss,acc = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            training_losses+=int(loss.detach())\n",
    "            training_accs+=int(acc.detach())\n",
    "            if step%100==0:\n",
    "                print(f\"STEP {step}, Training-acc = {training_accs/(step+1)}, Training-losses = {training_losses/(step+1)}\")\n",
    "        \n",
    "        ## Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        validation_loss, validation_acc = result['val_loss'], result['val_acc']\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "        ## summing up all the training and validation metrics\n",
    "        training_loss = training_losses/len(train_loader)\n",
    "        training_accs = training_accs/len(train_loader)\n",
    "        train_loss.append(training_loss)\n",
    "        train_acc.append(training_accs)\n",
    "        val_loss.append(validation_loss)\n",
    "        val_acc.append(validation_acc)\n",
    "\n",
    "        # plot training curves\n",
    "        plot_training_metrics(train_acc,val_acc,train_loss,val_loss)\n",
    "    return(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of the BosonSampler\n",
    "# here, we use 30 photons and 2 modes\n",
    "\n",
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "#session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session:\n",
    "    session.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bs = BosonSampler(30, 2, postselect = 2, session = None)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs.nb_parameters}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define device to run the model\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and send it to the appropriate device\n",
    "# set use_quantum = True if you want to use the boson sampler in input of the model\n",
    "model = MnistModel(device= device, use_quantum = True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the chosen parameters\n",
    "experiment = fit(epochs = 2, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end session if needed\n",
    "if session:\n",
    "    session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmw-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
